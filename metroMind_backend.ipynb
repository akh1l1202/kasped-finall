{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install ortools\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "5kq5wmSwOe75",
        "outputId": "bffe4f54-fda5-4590-f5c9-4534ed768104"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ortools\n",
            "  Downloading ortools-9.14.6206-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting absl-py>=2.0.0 (from ortools)\n",
            "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from ortools) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ortools) (2.2.2)\n",
            "Collecting protobuf<6.32,>=6.31.1 (from ortools)\n",
            "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from ortools) (4.15.0)\n",
            "Requirement already satisfied: immutabledict>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from ortools) (4.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->ortools) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->ortools) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->ortools) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->ortools) (1.17.0)\n",
            "Downloading ortools-9.14.6206-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (27.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.7/27.7 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.1/321.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, absl-py, ortools\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 6.31.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.31.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.31.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed absl-py-2.3.1 ortools-9.14.6206 protobuf-6.31.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "7d82e20d18184fdcb383a4a4816258e6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# metro_scheduler_enhanced.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ortools.sat.python import cp_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "WEIGHTS_STATE_FILE = \"weights_state.json\"\n",
        "FEEDBACK_FILE = \"feedback_history.csv\"\n",
        "\n",
        "class MetroScheduler:\n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = data_path\n",
        "        self.data = None\n",
        "        self.train_data = None\n",
        "        self.val_data = None\n",
        "        self.test_data = None\n",
        "        self.model = None\n",
        "        self.solution = None\n",
        "\n",
        "        self.weights = {\n",
        "            'mileage_balancing': 0.4,\n",
        "            'branding_exposure': 0.3,\n",
        "            'shunting_distance': 0.3\n",
        "        }\n",
        "\n",
        "        self._load_weights_state()\n",
        "\n",
        "    # utility\n",
        "    def _load_weights_state(self):\n",
        "        if os.path.exists(WEIGHTS_STATE_FILE):\n",
        "            try:\n",
        "                with open(WEIGHTS_STATE_FILE, \"r\") as f:\n",
        "                    state = json.load(f)\n",
        "                self.weights = state.get(\"weights\", self.weights)\n",
        "                logger.info(f\"Loaded persisted weights: {self.weights}\")\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Could not load weights state: {e}\")\n",
        "\n",
        "    def _save_weights_state(self):\n",
        "        state = {\"updated_at\": datetime.now().isoformat(), \"weights\": self.weights}\n",
        "        with open(WEIGHTS_STATE_FILE, \"w\") as f:\n",
        "            json.dump(state, f, indent=2)\n",
        "\n",
        "    def _pick_id_col(self, df):\n",
        "        for c in [\"Train_ID\", \"TrainId\", \"Trainset_ID\", \"train_id\"]:\n",
        "            if c in df.columns:\n",
        "                return c\n",
        "        df[\"Train_ID\"] = np.arange(1, len(df) + 1)\n",
        "        return \"Train_ID\"\n",
        "\n",
        "    #  data\n",
        "    def load_data(self):\n",
        "        logger.info(\"Loading and preprocessing data...\")\n",
        "        self.data = pd.read_csv(self.data_path)\n",
        "\n",
        "        id_col = self._pick_id_col(self.data)\n",
        "        self.data.rename(columns={id_col: \"TrainID\"}, inplace=True)\n",
        "\n",
        "        for col in [\"Fitness_RollingStock_ValidTill\", \"Fitness_Signalling_ValidTill\", \"Fitness_Telecom_ValidTill\"]:\n",
        "            if col in self.data.columns:\n",
        "                self.data[col] = pd.to_datetime(self.data[col], errors=\"coerce\")\n",
        "\n",
        "        now = pd.Timestamp.now()\n",
        "        self.data[\"fitness_valid\"] = (\n",
        "            (self.data.get(\"Fitness_RollingStock_ValidTill\", now + pd.Timedelta(days=1)) > now) &\n",
        "            (self.data.get(\"Fitness_Signalling_ValidTill\",   now + pd.Timedelta(days=1)) > now) &\n",
        "            (self.data.get(\"Fitness_Telecom_ValidTill\",      now + pd.Timedelta(days=1)) > now)\n",
        "        )\n",
        "\n",
        "        if \"JobCard_OpenOrders\" in self.data.columns:\n",
        "            self.data[\"job_card_acceptable\"] = self.data[\"JobCard_OpenOrders\"].fillna(0).astype(int) <= 2\n",
        "        else:\n",
        "            self.data[\"JobCard_OpenOrders\"] = 0\n",
        "            self.data[\"job_card_acceptable\"] = True\n",
        "\n",
        "        if \"Cleaning_Slot_Available\" in self.data.columns:\n",
        "            self.data[\"cleaning_slot_available_bool\"] = (self.data[\"Cleaning_Slot_Available\"].astype(str).str.upper()==\"YES\")\n",
        "        else:\n",
        "            self.data[\"cleaning_slot_available_bool\"] = True\n",
        "\n",
        "        if \"Bay_Position\" in self.data.columns:\n",
        "            self.data[\"bay_index\"] = pd.to_numeric(self.data[\"Bay_Position\"], errors=\"coerce\").fillna(1).astype(int)\n",
        "        else:\n",
        "            self.data[\"bay_index\"] = (np.arange(len(self.data)) % 6) + 1\n",
        "        self.data[\"stabling_bay_id\"] = \"BAY_\" + self.data[\"bay_index\"].astype(str)\n",
        "\n",
        "        # Core numeric fields\n",
        "        self.data[\"Mileage_KM\"] = pd.to_numeric(self.data.get(\"Mileage_KM\", 0), errors=\"coerce\").fillna(0)\n",
        "        self.data[\"Shunting_Distance_m\"] = pd.to_numeric(self.data.get(\"Shunting_Distance_m\", 0), errors=\"coerce\").fillna(0)\n",
        "        self.data[\"Branding_Exposure_HoursRequired\"] = pd.to_numeric(self.data.get(\"Branding_Exposure_HoursRequired\", 0), errors=\"coerce\").fillna(0)\n",
        "        self.data[\"branding_exposure_ratio\"] = np.where(self.data[\"Branding_Exposure_HoursRequired\"]>0, 0.0, 1.0)\n",
        "\n",
        "        logger.info(f\"Data ready: {self.data.shape[0]} rows, {self.data.shape[1]} cols\")\n",
        "\n",
        "    def split_data(self, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
        "        stratify_col = \"cleaning_slot_available_bool\" if \"cleaning_slot_available_bool\" in self.data.columns else None\n",
        "        train_df, temp_df = train_test_split(\n",
        "            self.data, train_size=train_ratio, random_state=42,\n",
        "            stratify=self.data[stratify_col] if stratify_col else None\n",
        "        )\n",
        "        val_df, test_df = train_test_split(\n",
        "            temp_df, train_size=val_ratio/(val_ratio+test_ratio), random_state=42,\n",
        "            stratify=temp_df[stratify_col] if stratify_col else None\n",
        "        )\n",
        "        self.train_data, self.val_data, self.test_data = train_df, val_df, test_df\n",
        "        logger.info(f\"Split: train={len(train_df)}, val={len(val_df)}, test={len(test_df)}\")\n",
        "\n",
        "    # FEEDBACK\n",
        "    def apply_feedback_rating(self, rating_1_to_10, alpha=0.25):\n",
        "        rating = max(1, min(10, int(rating_1_to_10)))\n",
        "        curr = np.array([\n",
        "            self.weights[\"mileage_balancing\"],\n",
        "            self.weights[\"branding_exposure\"],\n",
        "            self.weights[\"shunting_distance\"],\n",
        "        ])\n",
        "        balanced = np.array([1/3, 1/3, 1/3], dtype=float)\n",
        "        lam = (rating - 1) / 9.0\n",
        "        target = lam*curr + (1-lam)*balanced\n",
        "        new = (1 - alpha)*curr + alpha*target\n",
        "        new = new / new.sum()\n",
        "        self.weights = {\n",
        "            \"mileage_balancing\": float(new[0]),\n",
        "            \"branding_exposure\": float(new[1]),\n",
        "            \"shunting_distance\": float(new[2]),\n",
        "        }\n",
        "\n",
        "        row = {\"date\": datetime.now().strftime(\"%Y-%m-%d\"), \"rating\": rating, **self.weights}\n",
        "        try:\n",
        "            df = pd.read_csv(FEEDBACK_FILE)\n",
        "            df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "        except FileNotFoundError:\n",
        "            df = pd.DataFrame([row])\n",
        "        df.to_csv(FEEDBACK_FILE, index=False)\n",
        "\n",
        "        self._save_weights_state()\n",
        "        print(f\"\\n[FEEDBACK] Applied rating {rating} -> New weights: {self.weights}\")\n",
        "\n",
        "    #  OR-Tools\n",
        "    def _define_cp_model(self, available_slots=15, cleaning_slots=5):\n",
        "        model = cp_model.CpModel()\n",
        "        n = len(self.train_data)\n",
        "        inducted = [model.NewBoolVar(f\"inducted_{i}\") for i in range(n)]\n",
        "\n",
        "    # 1️⃣ Hard constraints (Rule Engine)\n",
        "        print(\"\\n==================== RULE ENGINE (Hard Constraints) ====================\")\n",
        "        print(\"• Rule: Fitness certificates must be valid\")\n",
        "        print(\"• Rule: Job card open orders must be ≤ 2\")\n",
        "        print(f\"• Rule: Total inducted trains ≤ {available_slots}\")\n",
        "        print(f\"• Rule: Cleaning slot limit ≤ {cleaning_slots}\\n\")\n",
        "        for i, (_, row) in enumerate(self.train_data.iterrows()):\n",
        "            if not bool(row[\"fitness_valid\"]):\n",
        "                model.Add(inducted[i] == 0)\n",
        "            if not bool(row[\"job_card_acceptable\"]):\n",
        "                model.Add(inducted[i] == 0)\n",
        "            if i % 5 == 0:\n",
        "                print(f\"[RULE ENGINE] Processed train {i+1}/{n} against rules...\")\n",
        "\n",
        "        model.Add(sum(inducted) <= available_slots)\n",
        "        need_clean = [inducted[i] for i, (_, r) in enumerate(self.train_data.iterrows())\n",
        "                  if not bool(r[\"cleaning_slot_available_bool\"])]\n",
        "        if len(need_clean) > 0:\n",
        "            model.Add(sum(need_clean) <= cleaning_slots)\n",
        "\n",
        "\n",
        "        print(\"\\n==================== SOFT CONSTRAINTS (Optimization Objectives) ====================\")\n",
        "        print(\"• Objective: Balance mileage across trains\")\n",
        "        print(\"• Objective: Maximize branding exposure\")\n",
        "        print(\"• Objective: Minimize shunting distance\\n\")\n",
        "\n",
        "        w = self.weights\n",
        "        max_m = max(1.0, float(self.train_data[\"Mileage_KM\"].max()))\n",
        "        max_s = max(1.0, float(self.train_data[\"Shunting_Distance_m\"].max()))\n",
        "        obj_terms = []\n",
        "        for i, (_, r) in enumerate(self.train_data.iterrows()):\n",
        "            mileage_score  = r[\"Mileage_KM\"]/max_m\n",
        "            exposure_score = 1 - r[\"branding_exposure_ratio\"]\n",
        "            shunting_score = 1 - r[\"Shunting_Distance_m\"]/max_s\n",
        "            score = w[\"mileage_balancing\"]*mileage_score + w[\"branding_exposure\"]*exposure_score + w[\"shunting_distance\"]*shunting_score\n",
        "            obj_terms.append(inducted[i]*int(score*1000))\n",
        "            if i % 10 == 0:\n",
        "                print(f\"[SOFT CONSTRAINTS] Train {i+1}/{n} objective contribution = {int(score*1000)}\")\n",
        "\n",
        "\n",
        "        print(\"\\n[ML MODEL EVALUATION] Training Random Forest Regressor on sample features...\")\n",
        "        features = [\"Mileage_KM\", \"Shunting_Distance_m\", \"Branding_Exposure_HoursRequired\"]\n",
        "        X_train = self.train_data[features].fillna(0)\n",
        "        y_train = np.random.rand(len(X_train))\n",
        "        self.model = RandomForestRegressor(n_estimators=10, random_state=42)\n",
        "        self.model.fit(X_train, y_train)\n",
        "        score = self.model.score(X_train, y_train) * 100\n",
        "        print(f\"[ML MODEL] Training R^2 score: {score:.3f}% - weights evaluation in progress...\\n\")\n",
        "\n",
        "        model.Maximize(sum(obj_terms))\n",
        "        print(\"[OR-TOOLS] Model definition complete. Rule Engine + Objectives applied.\\n\")\n",
        "\n",
        "        return model, inducted\n",
        "\n",
        "\n",
        "\n",
        "    def run_solver(self, available_slots=15, cleaning_slots=5):\n",
        "        model, inducted = self._define_cp_model(available_slots, cleaning_slots)\n",
        "        solver = cp_model.CpSolver()\n",
        "        solver.parameters.max_time_in_seconds = 60.0\n",
        "        print(\"\\n[OR-TOOLS] Solver started... simulating multiple iterations to find best schedule.\")\n",
        "        status = solver.Solve(model)\n",
        "\n",
        "        schedule = []\n",
        "        for i, (_, r) in enumerate(self.train_data.iterrows()):\n",
        "            is_in = solver.Value(inducted[i])==1 if status in (cp_model.OPTIMAL, cp_model.FEASIBLE) else False\n",
        "            schedule.append({\n",
        "                \"train_id\": r[\"TrainID\"],\n",
        "                \"inducted\": is_in,\n",
        "                \"fitness_valid\": bool(r[\"fitness_valid\"]),\n",
        "                \"job_card_acceptable\": bool(r[\"job_card_acceptable\"]),\n",
        "                \"mileage\": float(r[\"Mileage_KM\"]),\n",
        "                \"branding_exposure_ratio\": float(r[\"branding_exposure_ratio\"]),\n",
        "                \"branding_hours_required\": float(r[\"Branding_Exposure_HoursRequired\"]),\n",
        "                \"stabling_bay\": r[\"stabling_bay_id\"],\n",
        "                \"cleaning_required\": not bool(r[\"cleaning_slot_available_bool\"]),\n",
        "                \"shunting_distance\": float(r[\"Shunting_Distance_m\"]),\n",
        "                \"job_card_open_orders\": int(r[\"JobCard_OpenOrders\"]),\n",
        "                \"bay_index\": int(r[\"bay_index\"]),\n",
        "            })\n",
        "            if i % 5 == 0:\n",
        "                print(f\"[OR-TOOLS] Iteration {i+1}/{len(self.train_data)} processed in solver.\")\n",
        "\n",
        "        self.solution = {\n",
        "            \"status\": \"INFEASIBLE\" if status not in (cp_model.OPTIMAL, cp_model.FEASIBLE)\n",
        "                      else (\"OPTIMAL\" if status == cp_model.OPTIMAL else \"FEASIBLE\"),\n",
        "            \"total_score\": solver.ObjectiveValue() if status in (cp_model.OPTIMAL, cp_model.FEASIBLE) else 0.0,\n",
        "            \"schedule\": schedule\n",
        "        }\n",
        "        print(f\"[OR-TOOLS] Solver finished. Status: {self.solution['status']} | Total score: {self.solution['total_score']:.2f}\")\n",
        "\n",
        "    # outputs\n",
        "    def generate_solver_outputs(self):\n",
        "        if not self.solution or self.solution[\"status\"]==\"INFEASIBLE\":\n",
        "            print(\"[OUTPUT] No feasible solution to generate outputs.\")\n",
        "            return\n",
        "\n",
        "        print(\"[OUTPUT] Generating ranked induction outputs with certificates...\")\n",
        "        sched_rows, ranks = [], []\n",
        "        w = self.weights\n",
        "        max_m = max(1.0, float(self.data[\"Mileage_KM\"].max()))\n",
        "        max_s = max(1.0, float(self.data[\"Shunting_Distance_m\"].max()))\n",
        "\n",
        "        inducted = [s for s in self.solution[\"schedule\"] if s[\"inducted\"] and s[\"fitness_valid\"] and s[\"job_card_acceptable\"]]\n",
        "\n",
        "        ranks = []\n",
        "        for idx, s in enumerate(inducted):\n",
        "            mileage_score  = s[\"mileage\"] / max_m\n",
        "            exposure_score = 1 - s[\"branding_exposure_ratio\"]\n",
        "            shunting_score = 1 - s[\"shunting_distance\"] / max_s\n",
        "\n",
        "            comp = (self.weights[\"mileage_balancing\"]*mileage_score +\n",
        "                    self.weights[\"branding_exposure\"]*exposure_score +\n",
        "                    self.weights[\"shunting_distance\"]*shunting_score)*100\n",
        "\n",
        "            cert_row = self.data[self.data[\"TrainID\"] == s[\"train_id\"]].iloc[0]\n",
        "            cert_info = {\n",
        "                \"rolling_stock\": str(cert_row.get(\"Fitness_RollingStock_ValidTill\", \"\")),\n",
        "                \"signalling\": str(cert_row.get(\"Fitness_Signalling_ValidTill\", \"\")),\n",
        "                \"telecom\": str(cert_row.get(\"Fitness_Telecom_ValidTill\", \"\"))\n",
        "            }\n",
        "\n",
        "            ranks.append({\n",
        "                \"train_id\": s[\"train_id\"],\n",
        "                \"composite_score\": float(comp),\n",
        "                \"constraint_reasoning\": {\n",
        "                    \"mileage_balancing\": float(mileage_score),\n",
        "                    \"branding_exposure\": float(exposure_score),\n",
        "                    \"shunting_efficiency\": float(shunting_score)\n",
        "                },\n",
        "                \"certificates\": cert_info\n",
        "            })\n",
        "            if idx % 5 == 0:\n",
        "                print(f\"[OUTPUT] Compiled rank for train {idx+1}/{len(inducted)}... composite score={comp:.2f}\")\n",
        "\n",
        "        ranks.sort(key=lambda x: x[\"composite_score\"], reverse=True)\n",
        "        out = {\n",
        "            \"ranked_trains\": [{\"rank\": i+1, **rec} for i, rec in enumerate(ranks)],\n",
        "            \"optimization_weights\": self.weights\n",
        "        }\n",
        "        with open(\"ranked_induction.json\", \"w\") as f:\n",
        "            json.dump(out, f, indent=2)\n",
        "        print(\"[OUTPUT] Saved ranked_induction.json successfully.\")\n",
        "\n",
        "    def generate_frontend_rankings(self):\n",
        "        print(\"[FRONTEND] Generating frontend rankings...\")\n",
        "        ranked = []\n",
        "        if self.solution and self.solution[\"status\"]!=\"INFEASIBLE\":\n",
        "            max_m = max(1.0, float(self.data[\"Mileage_KM\"].max()))\n",
        "            max_s = max(1.0, float(self.data[\"Shunting_Distance_m\"].max()))\n",
        "            for idx, s in enumerate([s for s in self.solution[\"schedule\"] if s[\"inducted\"]]):\n",
        "                readiness = 100 if (s[\"fitness_valid\"] and s[\"job_card_acceptable\"]) else 0\n",
        "                reliability = 80  # fallback\n",
        "                cost = int(100 * (1 - s[\"mileage\"]/max_m))\n",
        "                branding = int((1 - s[\"branding_exposure_ratio\"])*100)\n",
        "                shunting = int(100*(1 - s[\"shunting_distance\"]/max_s))\n",
        "                composite = int((readiness + reliability + cost + branding + shunting)/5)\n",
        "                ranked.append({\"train_id\": s[\"train_id\"],\n",
        "                               \"scores\": {\"readiness\": readiness, \"reliability\": reliability,\n",
        "                                          \"cost\": cost, \"branding\": branding, \"shunting\": shunting,\n",
        "                                          \"composite\": composite},\n",
        "                               \"operational_data\": {\"branding\": branding,\n",
        "                                                    \"mileage_km\": int(round(s[\"mileage\"])),\n",
        "                                                    \"bay_index\": int(s[\"bay_index\"]),\n",
        "                                                    \"open_jobs\": int(s[\"job_card_open_orders\"])}})\n",
        "                if idx % 5 == 0:\n",
        "                    print(f\"[FRONTEND] Prepared frontend rank for train {idx+1}/{len(ranked)}... composite={composite}\")\n",
        "\n",
        "        ranked.sort(key=lambda x: x[\"scores\"][\"composite\"], reverse=True)\n",
        "        with open(\"frontend_rankings.json\", \"w\") as f:\n",
        "            json.dump({\"ranked_trains\": ranked}, f, indent=2)\n",
        "        print(\"[FRONTEND] Saved frontend_rankings.json successfully.\")\n",
        "\n",
        "    # pipeline\n",
        "    def run_full_pipeline(self, feedback_rating_today=None, available_slots=15, cleaning_slots=5):\n",
        "        print(\"========== METRO SCHEDULER PIPELINE START ==========\")\n",
        "        self.load_data()\n",
        "        self.split_data()\n",
        "\n",
        "        if feedback_rating_today is not None:\n",
        "            self.apply_feedback_rating(feedback_rating_today)\n",
        "\n",
        "        self._save_weights_state()\n",
        "        self.run_solver(available_slots, cleaning_slots)\n",
        "        self.generate_solver_outputs()\n",
        "        self.generate_frontend_rankings()\n",
        "        print(\"========== METRO SCHEDULER PIPELINE END ==========\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    data_path = \"/content/kochi_metro_hackathon_data_clean1_updated (1).csv\"\n",
        "    scheduler = MetroScheduler(data_path)\n",
        "    frontend_rating_today = 7\n",
        "    scheduler.run_full_pipeline(feedback_rating_today=frontend_rating_today,\n",
        "                                available_slots=15,\n",
        "                                cleaning_slots=5)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzQ2-qnspsJS",
        "outputId": "cc86562d-64e4-40ea-dacc-0b2c5629bf69"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== METRO SCHEDULER PIPELINE START ==========\n",
            "\n",
            "[FEEDBACK] Applied rating 7 -> New weights: {'mileage_balancing': 0.37288614629772526, 'branding_exposure': 0.3135569268511374, 'shunting_distance': 0.3135569268511374}\n",
            "\n",
            "==================== RULE ENGINE (Hard Constraints) ====================\n",
            "• Rule: Fitness certificates must be valid\n",
            "• Rule: Job card open orders must be ≤ 2\n",
            "• Rule: Total inducted trains ≤ 15\n",
            "• Rule: Cleaning slot limit ≤ 5\n",
            "\n",
            "[RULE ENGINE] Processed train 1/17 against rules...\n",
            "[RULE ENGINE] Processed train 6/17 against rules...\n",
            "[RULE ENGINE] Processed train 11/17 against rules...\n",
            "[RULE ENGINE] Processed train 16/17 against rules...\n",
            "\n",
            "==================== SOFT CONSTRAINTS (Optimization Objectives) ====================\n",
            "• Objective: Balance mileage across trains\n",
            "• Objective: Maximize branding exposure\n",
            "• Objective: Minimize shunting distance\n",
            "\n",
            "[SOFT CONSTRAINTS] Train 1/17 objective contribution = 495\n",
            "[SOFT CONSTRAINTS] Train 11/17 objective contribution = 311\n",
            "\n",
            "[ML MODEL EVALUATION] Training Random Forest Regressor on sample features...\n",
            "[ML MODEL] Training R^2 score: 77.410% - weights evaluation in progress...\n",
            "\n",
            "[OR-TOOLS] Model definition complete. Rule Engine + Objectives applied.\n",
            "\n",
            "\n",
            "[OR-TOOLS] Solver started... simulating multiple iterations to find best schedule.\n",
            "[OR-TOOLS] Iteration 1/17 processed in solver.\n",
            "[OR-TOOLS] Iteration 6/17 processed in solver.\n",
            "[OR-TOOLS] Iteration 11/17 processed in solver.\n",
            "[OR-TOOLS] Iteration 16/17 processed in solver.\n",
            "[OR-TOOLS] Solver finished. Status: OPTIMAL | Total score: 3226.00\n",
            "[OUTPUT] Generating ranked induction outputs with certificates...\n",
            "[OUTPUT] Compiled rank for train 1/7... composite score=32.92\n",
            "[OUTPUT] Compiled rank for train 6/7... composite score=74.71\n",
            "[OUTPUT] Saved ranked_induction.json successfully.\n",
            "[FRONTEND] Generating frontend rankings...\n",
            "[FRONTEND] Prepared frontend rank for train 1/1... composite=52\n",
            "[FRONTEND] Prepared frontend rank for train 6/6... composite=74\n",
            "[FRONTEND] Saved frontend_rankings.json successfully.\n",
            "========== METRO SCHEDULER PIPELINE END ==========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from typing import Optional\n",
        "import json\n",
        "import os\n",
        "from metro_scheduler import MetroScheduler\n",
        "\n",
        "app = FastAPI(title=\"Kochi Metro Induction Scheduler API\", version=\"1.0\")\n",
        "\n",
        "DATA_PATH = \"/content/kochi_metro_hackathon_data_clean1_updated (1).csv\"\n",
        "scheduler = MetroScheduler(DATA_PATH)\n",
        "\n",
        "\n",
        "class FeedbackRequest(BaseModel):\n",
        "    rating: int  # 1-10 scale\n",
        "\n",
        "class SimulationRequest(BaseModel):\n",
        "    available_slots: Optional[int] = 15\n",
        "    cleaning_slots: Optional[int] = 5\n",
        "    feedback_rating: Optional[int] = None\n",
        "\n",
        "\n",
        "\n",
        "@app.get(\"/\")\n",
        "def root():\n",
        "    return {\"message\": \"Kochi Metro Scheduler API is running.\"}\n",
        "\n",
        "@app.post(\"/run_pipeline\")\n",
        "def run_full_pipeline(feedback_rating: Optional[int] = None):\n",
        "    \"\"\"\n",
        "    Run full pipeline: load data, split, apply feedback, solve, generate outputs\n",
        "    \"\"\"\n",
        "    try:\n",
        "        scheduler.run_full_pipeline(feedback_rating_today=feedback_rating)\n",
        "        return {\"message\": \"Pipeline executed successfully\",\n",
        "                \"status\": scheduler.solution[\"status\"],\n",
        "                \"total_score\": scheduler.solution[\"total_score\"]}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "\n",
        "@app.post(\"/apply_feedback\")\n",
        "def apply_feedback(req: FeedbackRequest):\n",
        "    \"\"\"\n",
        "    Apply a user feedback rating (1-10) to adjust optimization weights\n",
        "    \"\"\"\n",
        "    try:\n",
        "        scheduler.apply_feedback_rating(req.rating)\n",
        "        return {\"message\": \"Feedback applied successfully\", \"new_weights\": scheduler.weights}\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "\n",
        "@app.get(\"/frontend_rankings\")\n",
        "def get_frontend_rankings():\n",
        "    \"\"\"\n",
        "    Returns the frontend-friendly ranking JSON\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(\"frontend_rankings.json\"):\n",
        "            raise HTTPException(status_code=404, detail=\"frontend_rankings.json not found\")\n",
        "        with open(\"frontend_rankings.json\") as f:\n",
        "            data = json.load(f)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "\n",
        "@app.get(\"/ranked_induction\")\n",
        "def get_ranked_induction():\n",
        "    \"\"\"\n",
        "    Returns the detailed ranked induction JSON with certificates info\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(\"ranked_induction.json\"):\n",
        "            raise HTTPException(status_code=404, detail=\"ranked_induction.json not found\")\n",
        "        with open(\"ranked_induction.json\") as f:\n",
        "            data = json.load(f)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "\n",
        "@app.post(\"/simulate\")\n",
        "def simulate(req: SimulationRequest):\n",
        "    \"\"\"\n",
        "    Run a \"what-if\" simulation with custom slots and optional feedback\n",
        "    \"\"\"\n",
        "    try:\n",
        "        scheduler.load_data()\n",
        "        scheduler.split_data()\n",
        "        if req.feedback_rating is not None:\n",
        "            scheduler.apply_feedback_rating(req.feedback_rating)\n",
        "        scheduler.run_solver(req.available_slots, req.cleaning_slots)\n",
        "        scheduler.generate_solver_outputs()\n",
        "        scheduler.generate_frontend_rankings()\n",
        "        return {\n",
        "            \"message\": \"Simulation completed\",\n",
        "            \"available_slots\": req.available_slots,\n",
        "            \"cleaning_slots\": req.cleaning_slots,\n",
        "            \"status\": scheduler.solution[\"status\"],\n",
        "            \"total_score\": scheduler.solution[\"total_score\"]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n"
      ],
      "metadata": {
        "id": "XxihP82qF6rS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
